---
title: "Tag 6 - Metadaten modellieren und Schnittstellen nutzen (1/2)"
date: 2021-12-02
---
Zu Beginn wurde das Thema Austauschprotokolle für Metadaten (nochmals) aufgegriffen. Dies fand ich sinnvoll, da ich bei der letzten Übung mit OAI-PMH nochmals recherchieren musste, was dies genau ist. So wurde auf die drei im Bibliotheks- und Archivbereich am weitesten verbreiteten Übertragungsprotokolle [Z39.50](https://de.wikipedia.org/wiki/Z39.50), [SRU](https://de.wikipedia.org/wiki/Search/Retrieve_via_URL) und [OAI-PMH](https://de.wikipedia.org/wiki/Open_Archives_Initiative) genauer eingegangen. Diese unterscheiden sich darin, dass Z39.50 und SRU für den Einzeldatenabgleich oder die Live-Suche genutzt werden während OAI-PMH eher für den Gesamtdatenabzug oder tägliche Aktualisierungen verwendet wird. 

In einem nächsten Schritt ging es darum, die erstellten Metadaten aus Archivesspace und Koha über die OAI-PMH Schnittstellen zu [«harvesten»](https://www.forschungsdaten.org/index.php/Harvesting), also zu sammeln. Hierfür mussten die Endpoints (Adresse unter welcher Schnittstelle verfügbar ist) von Koha und Archivesspace zuerst überprüft und Archivesspace mittels Terminals aktiv gestartet werden. Anschliessend installierten wir mittels Kommandos im Terminal ein OAI-Harvester Tool namens [VuFindHarvest](https://github.com/vufind-org/vufindharvest). Interessant finde ich, dass dieses über kein graphisches Interface verfügt, sondern nur über die Kommandozeile gesteuert werden kann, was etwas gewöhnungsbedürftig ist. 

So führten wir im nächsten Step das eigentliche Harvesting durch. Dieses wurde mit folgenden Befehlen ausgeführt, wobei die Parameter url, metadataPrefix und das Zielverzeichnis des zweiten Befehls noch auf unsere Datenquellen hin angepasst werden mussten.

cd ~/vufindharvest-4.1.0

php bin/harvest_oai.php --url=http://example.com/oai_server --metadataPrefix=oai_dc my_target_dir

php (Wir wollen php Programm aufrufen) bin (Aufrufen des Programms) url (Wie ist URL-Schnittstelle erreichbar?) metadataPrefix (Welches Format soll aus Schnittstelle abgefragt werden?) Angabe des Zielverzeichnisses

![image](https://user-images.githubusercontent.com/90821878/151664810-824b4248-95d0-4779-848f-57cc2deb8bab.png)

Harvesting von Koha im Terminal

Bei der ersten Eingabe erhielt ich deshalb auch eine Fehlermeldung, da ich wahrscheinlich einen Tippfehler gemacht hatte. Beim zweiten Versuch hat es allerdings funktioniert und die Datensätze lagen als [XML](https://de.wikipedia.org/w/index.php?title=Extensible_Markup_Language&oldid=217526822)-Datei in den entsprechenden Ordnern. 

![image](https://user-images.githubusercontent.com/90821878/151664443-19660f29-90b0-4e6b-8555-ca602069cbbf.png)

Beispiel geharvestete Dateien von Koha

Nun ging es darum, die Datensätze in ein gemeinsames Format zu bringen. Hierfür verwendeten wir [Crosswalks](https://guides.lib.utexas.edu/metadata-basics/crosswalks). Dabei sollen Daten aus einem Metadatenstandard, ausgedrückt in einem Metadatenformat, in einen anderen gebracht bzw. konvertiert werden. Im Crosswalk enthalten sind Regeln, wie Elemente und Werte zugeordnet werden sollen. Diese Zuordnung funktioniert in der Regel nicht verlustfrei und so ist es wichtig, dass zuerst ein Vergleich der Formate stattfindet. In diesem Zusammenhang ist auch [XSLT](https://de.wikipedia.org/w/index.php?title=XSL_Transformation&oldid=214891883) zu nennen, eine Programmiersprache zur Transformation von XML-Dokumenten.

In unserem Beispiel haben wir Daten im Standard EAD (Archivesspace) und DC (DSpace), welche nun einheitlich in MARC1-XML konvertiert werden sollen. Die Daten von Koha sind bereits im Format MARC21-XML.

Für die Konvertierung benutzten wir das Tool [MarcEdit7](https://en.wikipedia.org/wiki/MarcEdit), welches wir zuerst wieder installieren und bestimmte Konfigurationen vornehmen mussten. Anschliessend konnte die Konvertierung stattfinden, in dem die entsprechenden XML-Files von Archivesspace und DSpace ausgewählt und eine Zieldatei definiert wurde. Auch die entsprechende Operation (also von welchem Format in welches Format soll konvertiert werden) musste ausgewählt werden. Wichtig ist, dass dieses Tool keine direkte Transformation von EAD in MARCXML vornehmen kann, so dass EAD zuerst in MARC (s. Grafik) und von MARC in MARCXML umgewandelt werden muss. 

![image](https://user-images.githubusercontent.com/90821878/151665679-bc164628-ef47-42bb-aa06-77346febb073.png)

Der anschliessende Vergleich der Ausgangsdatei in EAD zur Zieldatei zeigte auch nochmals auf, dass die Konvertierung nicht verlustfrei durchgeführt werden kann und so in der Zieldatei viele Elemente fehlen. Die Konvertierung der DSpace-Datei von OAIDC in MARCXML funktionierte wesentlich besser (wie untenstehende Bilder zeigen).


![Screenshot from 2021-12-05 10-21-07](https://user-images.githubusercontent.com/90821878/144741454-dbca9e6a-f954-454b-bf2c-5c4f70c5414b.png)

Links: Archivesspace-Daten nach EAD in XML _________________________ Rechts: Archivesspace-Daten konvertiert in MARCXML

![Screenshot from 2021-12-05 10-26-54](https://user-images.githubusercontent.com/90821878/144741455-4672907f-3728-4624-bd70-3c50108768db.png)

Links: DSpace-Daten nach DC in XML _______________________________________ Rechts: DSpace-Daten konvertiert in MARCXML

Die Themen der heutigen Vorlesung waren für mich völliges Neuland und teilweise doch sehr «terminallastig». Dennoch konnte ich alle Aufgaben problemlos lösen. Abschliessend stellt sich mir die Frage in welchen Anwendungsfällen diese Crosswalks in der Praxis tatsächlich genutzt werden.

(Quelle: Unterrichtsskript BAIN HS21 ISc18tzZ Tag 6 (02.12.)
