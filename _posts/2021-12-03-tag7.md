---
title: "Tag 7 - Metadaten modellieren und Schnittstellen nutzen (2/2)"
date: 2021-12-03
---
Da ich an der 6. Vorlesung nicht teilnehmen konnte und mir die Aufnahme erst nach der 7. Vorlesung angeschaut habe, hatte ich zu Beginn der 7. Vorlesung Schwierigkeiten in die Thematik einzusteigen, weil mir gewisses Grundwissen bezüglich Metadatentransformation (s. [Artikel 6](https://github.com/MomoVasco/Lerntagebuch/blob/675cc71a581318f1a30bae4c54c4649269fe7eb4/_posts/2021-12-02-tag6.md)) der 6. Vorlesung fehlte. 

Gut fand ich, dass die zwei Vorlesungen bezüglich Übungen und Tools in sich abgeschlossen waren. So schauten wir uns in der 7. Sitzung eine neue Software zur Metadatentransformation namens [OpenRefine](https://openrefine.org/) an. OpenRefine ist ein Tool zur Analyse, Bereinigung, Konvertierung und Anreicherung von Daten.  Es verfügt über eine grafische Oberfläche und wird lokal installiert sowie anschliessend über den Browser bedient. OpenRefine ist besonders für tabellarische Daten, wie wir sie beispielsweise aus Excel kennen, geeignet.

Das Tool musste zuerst wieder mittels Terminals und Kommandos installiert werden. Neu war für mich, dass wenn man eine Datei im Verzeichnis, in welchem man sich gerade befindet, aufrufen möchte, ein ./ vor die Datei gesetzt werden muss. Dies damit das System weiss, dass ich eine Datei im aktuellen Verzeichnis und nicht einen Befehl meine.

Nachdem wir Beispieldaten (Datensätze über Zeitschriften) mittels URL in OpenRefine importiert hatten, erschienen die rund 1000 Datensätze in einer Ansicht, die an eine Mischung aus Tabellenverarbeitung (mit Spalten & Zeilen) und Suchmaschine erinnert.

![image](https://user-images.githubusercontent.com/90821878/151666646-1c1ee50e-c95f-48aa-a75b-920ecebe14de.png)


Eine der wichtigsten Funktionen von OpenRefine sind die Filter, auch Facets (Facetten) genannt. Mittels Textfacette, angewandt auf die Spalte "Language", erscheinen alle Werte, welche in dieser Spalte vergeben wurden mit entsprechender Anzahl Objekte. Spannend fand ich hierbei, dass die Werte direkt bearbeitet werden können. Also beispielsweise "English" in "EN" umgewandelt werden kann und die, mit "English" verknüpften Objekte, dann automatisch zu der bereits bestehenden Anzahl "EN" Objekte hinzugezählt werden. 

![Textfacette](https://user-images.githubusercontent.com/90821878/145689451-3464e7dd-370e-460f-a381-1a8c7a2552fd.png)

Textfacette "Language"

Ein weiteres Thema der Vorlesung war die Reconciliation, sprich der Abgleich und die Anreicherung der Datensätze mit externen Daten. In unserem Fall war das [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page). Diese Funktion erscheint mir sehr sinnvoll, da so auch Daten aus anderen Quellen genutzt werden können und nicht jeder das Rad wieder neu erfinden muss.

Der wichtigste Teil der Vorlesung beschäftigte sich wiederum mit der Metadatentransformation (s. [Artikel 6](https://github.com/MomoVasco/Lerntagebuch/blob/675cc71a581318f1a30bae4c54c4649269fe7eb4/_posts/2021-12-02-tag6.md)). Dabei haben wir eine Transformation der vorliegenden Daten im Format [CSV](https://de.wikipedia.org/w/index.php?title=CSV_(Dateiformat)&oldid=218964806) von OpenRefine zum Metadatenformat MARC21XML vorgenommen. Hierfür mussten wir mittels eines Templates modellieren, wie die Struktur unseres MARC21XML-Ergebnisses aussehen sollte (s. Grafik). In diesem Template sind auch die Transformationsregeln definiert, beispielsweise, dass mehrere Werte innerhalb einer Zelle auf mehrere Felder aufgeteilt werden sollen.  Wir orientierten uns hierbei an einem [Datensatz](https://www.loc.gov/standards/marcxml/xml/collection.xml) der Library of Congress.

![image](https://user-images.githubusercontent.com/90821878/151667189-daaa0d4c-7d26-4947-947b-eb9a7566356d.png)

Anschliessend konnten wir das Ergebnis als Textdatei exportieren, welche wir noch in eine XML-Datei umbenennen mussten (anstatt .txt -> .xml). Als letzter Schritt folgte eine Validierung unserer Datei gegen das offizielle MARC21-Schema, um zu überprüfen, ob wir keine Fehler gemacht haben (s. Grafik).

![image](https://user-images.githubusercontent.com/90821878/151667369-eac3b39e-5129-42f8-a2a4-6d128b45aa87.png)

Da wir bereits anspruchsvolle Übungen in dieser Vorlesung gemacht hatten, fand ich es schwierig, mich auf diesen abschliessenden, doch recht komplizierten, Themenblock zu konzentrieren, obwohl vieles vorgezeigt wurde. So habe ich mir im Nachhinein nochmals die Aufzeichnung angeschaut und konnte einige Verständnislücken schliessen. 

Abschliessend kann ich sagen, dass mir OpenRefine als ein praktisches Tool erscheint, um Daten auf einfache Weise zu bereinigen. Da ich gewisse Schwierigkeiten mit Excel habe und an meinem Arbeitsort noch mit Exceldateien gearbeitet wird, wäre OpenRefine möglicherweise eine gute Ergänzung, um eine optimale Datenkonsistenz zu erreichen. So fand ich es trotz fehlender Vorkenntnisse spannend, dieses Tool kennenzulernen.

Quelle: [Unterrichtsskript BAIN HS21 ISc18tzZ Tag 7 (03.12.)](https://pad.gwdg.de/qG3buOGLTxqCm6YbdU1j_Q?view)
